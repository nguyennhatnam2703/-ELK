# Tìm hiểu về Logstash

# 1.Logstash là gì ?

- `Logstash` là một công cụ mạnh mẽ cho việc nhận tập trung và phân tích log, giúp cho bạn có một cái nhìn về môi trường và hoạt động của server.

- Bao gồm ba giai đoạn trong chuỗi xử lý sự kiện log tương ứng ba module:

 + `INPUT`: Tiếp nhận/thu thập dữ liệu sự kiện log ở dạng thô từ các nguồn khác nhau như file, redis, rabbitmq, beats, syslog,….
 + `FILTER`: Sau khi tiếp nhận dữ liệu sẽ tiến hành thao tác dữ liệu sự kiện log (như thêm,xóa,thay thế,.. nội dung log) theo cấu hình của quản trị viên để xây dựng
lại cấu trúc dữ liệu log event theo mong muốn. 
 + `OUTPUT`: Sau cùng sẽ thực hiện chuyển tiếp dữ liệu sự kiện log về các dịch vụ khác như Elasticsearch tiếp nhận lưu trữ log hoặc hiển thị log,...
 
# 2.Workflow:

- ![]( /image/log1.png)

- Ở bước INPUT, Logstash sẽ được cấu hình lựa chọn hình thức tiếp nhận log event hoặc đi lấy dữ liệu log ở dịch remote theo nhu cầu. Sau khi lấy được log event 
thì , khâu INPUT sẽ ghi dữ liệu event xuống hàng đợi tập trung ở bộ nhớ RAM hoặc trên ổ cứng.

- Mỗi pipeline worker thread sẽ tiếp tục lấy một loạt sự kiện đang nằm trong hàng đợi này để xử lý FILTER giúp tái cấu trúc dữ liệu log sẽ được gửi đi ở phần 
OUTPUT. Số lượng sự kiện được xử lý một loạt và số lượng pipeline worker thread có thể được cấu hình tinh chỉnh tối ưu hơn, nội dung này có thể đề cập ở phần 
khác.

- Mặc định Logstash sử dụng hàng đợi nằm trong bộ nhớ RAM giữa các giai đoạn (input -> filter và filter -> output) để làm bộ đệm lưu trữ dữ liệu event trước khi
 xử lý. Nếu mà chương trình dịch vụ Logstash của bạn vì một lý do nào đó bị dừng hoạt động giữa chừng, thì các dữ liệu event đang nằm trong buffer sẽ bị mất.
 
## INPUT:

- Một số Input plugin phổ biến thường được sử dụng để nhận/lấy log như :

  + file: đọc dữ liệu từ file trên filesystem, giống lệnh ‘tail -f’ trên UNIX.
  + syslog: chương trình Logstash sẽ lắng nghe trên port 514 để tiếp nhận dữ liệu syslog.
  + redis: đọc dữ liệu log từ redis server, sử dụng cả 2 cơ chế redis channel và redis lists.
  + beats: xử lý các dữ liệu thông tin được gửi từ chương trình Beats 
 `Logstash` có hỗ trợ khá nhiều loại plugin input khác nhau giúp bạn linh động trong việc nhận nguồn dữ liệu log. 

## FILTER:

- Bạn có thể kết hợp filter với các điều kiện so sánh nhằm thực hiện 1 tác vụ hành động (action) khi một sự kiện thoả mãn khớp với các tiêu chí do bạn được ra.
 Một số filter plugin hữu ích như : 
 
  + grok: Nếu bạn gặp một dữ liệu sự kiện log với cấu trúc văn bản không phổ biến hoặc là phức tạp. Thì Grok hiện là plugin filter tốt nhất để phân tích cú 
  pháp dữ liệu log không được cấu trúc văn bản thành một thứ có cấu trúc và có thể truy vấn được. 
  + mutate: thực hiện sự thay đổi trên thông tin sự kiện log như: đổi tên, xoá, thay thế, tinh chỉnh các trường (field) thông tin của sự kiện log.
  + drop: dừng xử lý sự kiện ngay lập tức, ví dụ các ‘debug event’.
  + clone: tạo một bản copy của sự kiện.
  + geoip: thêm thông tin về vị trí địa lý của địa chỉ IP (thường để hiển thị biểu đồ trên Kibana)
  
## OUTPUT:
  
- Output là bước cuối cùng trong chuỗi các bước xử lý của Logstash. Một sự kiện có thể đưa qua nhiều output khác nhau, tiếp đây là các Output plugin hay sử 
dụng:

  + elasticsearch: gửi dữ liệu sự kiện đến hệ thống Elasticsearch. Tất nhiên đầu cuối của hệ thống logging ELK thường là Elasticsearch giúp bạn lưu trữ log, 
  tìm kiếm log, …
  + file: nếu bạn chả cần bất kì sự lưu trữ log cho việc tìm kiếm, hiển thị,… thì có thể lưu ra file trên hệ thống.
  + graphite: một trong những tool mã nguồn mở hỗ trợ việc lưu trữ và tạo biểu đồ metric.
  + statsd: gửi dữ liệu tới dịch vụ ‘statsd’.
  
# Tham khảo:

- [1] https://cuongquach.com/elk-tim-hieu-dich-vu-logstash-trong-he-thong-elk-stack-logging.html

- [2] https://github.com/TrongTan124/ghi-chep-ELK-OPS/blob/master/tim-hieu-ve-Logstash.md  


